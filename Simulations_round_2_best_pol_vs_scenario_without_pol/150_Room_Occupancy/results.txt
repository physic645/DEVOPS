The best        is: {'learning_rate': 0.0001, 'layers': 5, 'units_0': 5, 'act_0': 'h_2nd', 'units_1': 30, 'act_1': 'relu', 'units_2': 5, 'act_2': 'relu', 'units_3': 30, 'act_3': 'relu', 'units_4': 5, 'act_4': 'relu'} 


The second best is: {'learning_rate': 0.0001, 'layers': 5, 'units_0': 5, 'act_0': 'relu', 'units_1': 5, 'act_1': 'relu', 'units_2': 30, 'act_2': 'relu', 'units_3': 5, 'act_3': 'relu', 'units_4': 5, 'act_4': 'h_2nd'} 


The scenario without pol is: {'learning_rate': 0.0001, 'layers': 3, 'units_0': 5, 'act_0': 'relu', 'units_1': 25, 'act_1': 'relu', 'units_2': 30, 'act_2': 'relu', 'units_3': 30, 'act_3': 'relu', 'units_4': 5, 'act_4': 'relu'} 





The associated times were: 

The total time for hypertuning the Room Occupancy dataset was: 4430.900 seconds 

The total time for training the Room Occupancy dataset for the 3 best models for 100 epochs was: 136.985 seconds 

The whole process took total 4569.256 seconds 


 We trained the Room Occupancy dataset made by Sachin Sharma 
