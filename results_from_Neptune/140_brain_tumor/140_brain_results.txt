The best        is: {'learning_rate': 0.01, 'layers': 3, 
'units_0': 5, 'act_0': 'h_2nd', 
'units_1': 30, 'act_1': 'h_2nd', 
'units_2': 30, 'act_2': 'relu', 
'units_3': 5, 'act_3': 'relu', 
'units_4': 5, 'act_4': 'relu'} 


The second best is: {'learning_rate': 0.01, 'layers': 3, 
'units_0': 5, 'act_0': 'h_2nd', 
'units_1': 30, 'act_1': 'h_2nd', 
'units_2': 30, 'act_2': 'relu', 
'units_3': 5, 'act_3': 'relu', 
'units_4': 25, 'act_4': 'h_2nd'} 


The third_best  is: {'learning_rate': 0.01, 'layers': 3, 
'units_0': 30, 'act_0': 'h_2nd', 
'units_1': 30, 'act_1': 'h_2nd', 
'units_2': 30, 'act_2': 'relu', 
'units_3': 5, 'act_3': 'relu', 
'units_4': 25, 'act_4': 'relu'} 


The fourth_best is: {'learning_rate': 0.01, 'layers': 3, 'units_0': 5, 'act_0': 'h_2nd', 'units_1': 30, 'act_1': 'h_2nd', 'units_2': 30, 'act_2': 'relu', 'units_3': 30, 'act_3': 'relu', 'units_4': 30, 'act_4': 'relu'} 


The fifth_best  is: {'learning_rate': 0.01, 'layers': 3, 'units_0': 25, 'act_0': 'h_2nd', 'units_1': 30, 'act_1': 'h_2nd', 'units_2': 30, 'act_2': 'relu', 'units_3': 30, 'act_3': 'relu', 'units_4': 10, 'act_4': 'h_2nd'}

The associated times were: 

The total time for hypertuning the Brain Tumor dataset was: 1808.272 seconds 

The total time for training the Brain Tumor dataset for the 5 best models for 100 epochs was: 31.395 seconds 

The whole process took total 1841.589 seconds 


 We trained the Brain Tumor dataset made by Jillani Soft Tech 
